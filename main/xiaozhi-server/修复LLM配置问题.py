#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤LLMé…ç½®MissingParameteré”™è¯¯
è¯Šæ–­å’Œä¿®å¤DeepSeek APIè°ƒç”¨é—®é¢˜
"""

import yaml
import json
import logging
import sys
import os
from typing import Dict, Any, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger('LLMé…ç½®ä¿®å¤')

def load_current_config() -> Dict[str, Any]:
    """åŠ è½½å½“å‰é…ç½®"""
    try:
        with open('config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        logger.info("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        return config
    except Exception as e:
        logger.error(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return {}

def test_deepseek_api_direct():
    """ç›´æ¥æµ‹è¯•DeepSeek APIè°ƒç”¨"""
    logger.info("ğŸ§ª ç›´æ¥æµ‹è¯•DeepSeek API")
    
    try:
        import requests
        import time
        
        # å½“å‰é…ç½®
        api_key = "ba769173-7dc6-43c5-b402-c1d08606e242"
        base_url = "https://ark.cn-beijing.volces.com/api/v3"
        model_name = "deepseek-v3-250324"
        
        # æµ‹è¯•è¯·æ±‚
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        payload = {
            "model": model_name,
            "messages": [
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·è¯´ä¸€å¥è¯æµ‹è¯•"}
            ],
            "max_tokens": 50,
            "temperature": 0.7
        }
        
        logger.info(f"ğŸ“¤ å‘é€è¯·æ±‚åˆ°: {base_url}/chat/completions")
        logger.info(f"   æ¨¡å‹: {model_name}")
        logger.info(f"   APIå¯†é’¥: {api_key[:20]}...")
        
        response = requests.post(
            f"{base_url}/chat/completions",
            headers=headers,
            json=payload,
            timeout=30
        )
        
        logger.info(f"ğŸ“¥ å“åº”çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            content = result.get("choices", [{}])[0].get("message", {}).get("content", "æ— å†…å®¹")
            logger.info(f"âœ… APIè°ƒç”¨æˆåŠŸ!")
            logger.info(f"   å“åº”å†…å®¹: {content}")
            return True
        else:
            error_detail = response.text
            logger.error(f"âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code}")
            logger.error(f"   é”™è¯¯è¯¦æƒ…: {error_detail}")
            
            # åˆ†æå…·ä½“é”™è¯¯
            if "MissingParameter" in error_detail:
                logger.error("ğŸ” MissingParameteré”™è¯¯åˆ†æ:")
                logger.error("   å¯èƒ½åŸå› : è¯·æ±‚ç¼ºå°‘å¿…è¦å‚æ•°")
            elif "invalid_request_error" in error_detail:
                logger.error("ğŸ” Invalid requesté”™è¯¯:")
                logger.error("   å¯èƒ½åŸå› : APIå¯†é’¥æ— æ•ˆæˆ–æ¨¡å‹åç§°é”™è¯¯")
            elif "authentication" in error_detail.lower():
                logger.error("ğŸ” è®¤è¯é”™è¯¯:")
                logger.error("   å¯èƒ½åŸå› : APIå¯†é’¥æ— æ•ˆæˆ–è¿‡æœŸ")
            
            return False
            
    except Exception as e:
        logger.error(f"âŒ APIæµ‹è¯•å¼‚å¸¸: {e}")
        return False

def try_alternative_configs():
    """å°è¯•æ›¿ä»£é…ç½®"""
    logger.info("ğŸ”§ å°è¯•æ›¿ä»£é…ç½®")
    
    # æ›¿ä»£é…ç½®åˆ—è¡¨
    alternatives = [
        {
            "name": "DeepSeekå®˜æ–¹API",
            "api_key": "ba769173-7dc6-43c5-b402-c1d08606e242",
            "base_url": "https://api.deepseek.com/v1",
            "model_name": "deepseek-chat"
        },
        {
            "name": "ç«å±±å¼•æ“æ ‡å‡†æ ¼å¼",
            "api_key": "ba769173-7dc6-43c5-b402-c1d08606e242", 
            "base_url": "https://ark.cn-beijing.volces.com/api/v3",
            "model_name": "deepseek-chat"  # å°è¯•æ ‡å‡†æ¨¡å‹å
        },
        {
            "name": "å…¼å®¹æ¨¡å¼æµ‹è¯•",
            "api_key": "ba769173-7dc6-43c5-b402-c1d08606e242",
            "base_url": "https://ark.cn-beijing.volces.com/api/v3",
            "model_name": "gpt-3.5-turbo"  # ä½¿ç”¨é€šç”¨æ¨¡å‹å
        }
    ]
    
    for alt in alternatives:
        logger.info(f"ğŸ§ª æµ‹è¯•é…ç½®: {alt['name']}")
        
        try:
            import requests
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {alt['api_key']}"
            }
            
            payload = {
                "model": alt['model_name'],
                "messages": [{"role": "user", "content": "æµ‹è¯•"}],
                "max_tokens": 20,
                "temperature": 0.7
            }
            
            response = requests.post(
                f"{alt['base_url']}/chat/completions",
                headers=headers,
                json=payload,
                timeout=15
            )
            
            if response.status_code == 200:
                logger.info(f"âœ… {alt['name']} é…ç½®å·¥ä½œæ­£å¸¸!")
                return alt
            else:
                logger.warning(f"âŒ {alt['name']} å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            logger.warning(f"âŒ {alt['name']} å¼‚å¸¸: {e}")
    
    return None

def create_fixed_config(working_config: Dict[str, Any]):
    """åˆ›å»ºä¿®å¤åçš„é…ç½®"""
    logger.info("ğŸ“ åˆ›å»ºä¿®å¤åçš„é…ç½®")
    
    # åŠ è½½å½“å‰é…ç½®
    config = load_current_config()
    if not config:
        return
    
    # æ›´æ–°LLMé…ç½®
    if "LLM" in config and "ChatGLMLLM" in config["LLM"]:
        config["LLM"]["ChatGLMLLM"].update({
            "api_key": working_config["api_key"],
            "base_url": working_config["base_url"], 
            "model_name": working_config["model_name"],
            "type": "openai"
        })
        
        # å¤‡ä»½åŸé…ç½®
        import time
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        backup_file = f"config_backup_llm_fix_{timestamp}.yaml"
        
        try:
            with open(backup_file, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, ensure_ascii=False, default_flow_style=False)
            logger.info(f"ğŸ’¾ åŸé…ç½®å·²å¤‡ä»½åˆ°: {backup_file}")
        except Exception as e:
            logger.warning(f"âš ï¸ é…ç½®å¤‡ä»½å¤±è´¥: {e}")
        
        # å†™å…¥æ–°é…ç½®
        try:
            with open('config.yaml', 'w', encoding='utf-8') as f:
                yaml.dump(config, f, ensure_ascii=False, default_flow_style=False)
            
            logger.info("âœ… é…ç½®æ›´æ–°æˆåŠŸ!")
            logger.info("ğŸ“‹ æ–°çš„LLMé…ç½®:")
            logger.info(f"   APIå¯†é’¥: {working_config['api_key'][:20]}...")
            logger.info(f"   åŸºç¡€URL: {working_config['base_url']}")
            logger.info(f"   æ¨¡å‹åç§°: {working_config['model_name']}")
            
        except Exception as e:
            logger.error(f"âŒ é…ç½®å†™å…¥å¤±è´¥: {e}")

def test_local_llm_call():
    """æµ‹è¯•æœ¬åœ°LLMè°ƒç”¨"""
    logger.info("ğŸ§ª æµ‹è¯•æœ¬åœ°LLMè°ƒç”¨")
    
    try:
        from config.config_loader import load_config
        from core.utils import llm as llm_utils
        
        # é‡æ–°åŠ è½½é…ç½®
        config = load_config()
        
        # è·å–LLMé…ç½®
        llm_config = config.get("LLM", {})
        selected_llm = config.get("selected_module", {}).get("LLM", "ChatGLMLLM")
        
        if selected_llm not in llm_config:
            logger.error(f"âŒ æœªæ‰¾åˆ°LLMé…ç½®: {selected_llm}")
            return False
        
        # åˆ›å»ºLLMå®ä¾‹
        llm_type = llm_config[selected_llm].get("type", selected_llm)
        llm_instance = llm_utils.create_instance(llm_type, llm_config[selected_llm])
        
        # æµ‹è¯•è°ƒç”¨
        test_messages = [
            {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•å›å¤ä¸€å¥è¯æµ‹è¯•"}
        ]
        
        logger.info("ğŸ“¤ æµ‹è¯•LLMè°ƒç”¨...")
        response = llm_instance.chat(test_messages)
        
        if response and len(response.strip()) > 0:
            logger.info(f"âœ… LLMè°ƒç”¨æˆåŠŸ!")
            logger.info(f"   å“åº”: {response}")
            return True
        else:
            logger.error("âŒ LLMè¿”å›ç©ºå“åº”")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æœ¬åœ°LLMè°ƒç”¨å¤±è´¥: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ”§ LLMé…ç½®MissingParameteré”™è¯¯ä¿®å¤å·¥å…·")
    logger.info("="*50)
    
    # 1. æµ‹è¯•å½“å‰é…ç½®
    logger.info("ğŸ” æ­¥éª¤1: æµ‹è¯•å½“å‰DeepSeeké…ç½®")
    current_works = test_deepseek_api_direct()
    
    if current_works:
        logger.info("âœ… å½“å‰é…ç½®æ­£å¸¸ï¼Œé—®é¢˜å¯èƒ½åœ¨åˆ«å¤„")
        logger.info("ğŸ’¡ å»ºè®®æ£€æŸ¥:")
        logger.info("   1. LLMè°ƒç”¨çš„å‚æ•°ä¼ é€’")
        logger.info("   2. å¼‚æ­¥è°ƒç”¨çš„é”™è¯¯å¤„ç†")
        logger.info("   3. ç½‘ç»œè¿æ¥ç¨³å®šæ€§")
    else:
        # 2. å°è¯•æ›¿ä»£é…ç½®
        logger.info("ğŸ” æ­¥éª¤2: å°è¯•æ›¿ä»£é…ç½®")
        working_config = try_alternative_configs()
        
        if working_config:
            logger.info(f"âœ… æ‰¾åˆ°å¯ç”¨é…ç½®: {working_config['name']}")
            
            # 3. æ›´æ–°é…ç½®æ–‡ä»¶
            logger.info("ğŸ” æ­¥éª¤3: æ›´æ–°é…ç½®æ–‡ä»¶")
            create_fixed_config(working_config)
            
            # 4. æµ‹è¯•æœ¬åœ°è°ƒç”¨
            logger.info("ğŸ” æ­¥éª¤4: æµ‹è¯•ä¿®å¤åçš„æœ¬åœ°è°ƒç”¨")
            if test_local_llm_call():
                logger.info("ğŸ‰ LLMé…ç½®ä¿®å¤æˆåŠŸ!")
                logger.info("ğŸ’¡ è¯·é‡å¯PythonæœåŠ¡ä»¥ä½¿é…ç½®ç”Ÿæ•ˆ")
            else:
                logger.error("âŒ æœ¬åœ°è°ƒç”¨ä»æœ‰é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")
        else:
            logger.error("âŒ æ‰€æœ‰é…ç½®éƒ½å¤±è´¥")
            logger.info("ğŸ’¡ å»ºè®®:")
            logger.info("   1. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ")
            logger.info("   2. è”ç³»DeepSeekæ”¯æŒ")
            logger.info("   3. æš‚æ—¶åˆ‡æ¢åˆ°å…¶ä»–LLMæä¾›å•†")

if __name__ == "__main__":
    main()
